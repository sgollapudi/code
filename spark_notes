Spark supports two types of shared variables: broadcast variables, which can be used to cache a value in memory on all nodes, and accumulators, which are variables that are only “added” to, such as counters and sums.

spark.conf.set ==> Below variables
spark.sql.join.preferSortMergeJoin --> true to use it by default
spark.sql.shuffle.partitions ==> Total partitions
spark.sql.autoBroadcastJoinThreshold ==> Maximum size in bytes of table that would be broadcast.
