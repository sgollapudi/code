Commonly used properties

-Dmapreduce.job.reduces=<total>
-Dmapreduce.job.queuename=<queue name>

For analyzing JVM dump --> eclipse plugin jvisualvm

Code inside main/run 

Incase no reducers are required, set job.setNumReduceTasks(0)
Where as part of Mapper we are reading from Hbase--> TableMapReduceUtil.initTableMapperJob(<hbase table name>, <Hbase scan object>,<Mapper class>, <mapper output key>, <mapper output value>, job);

Code for making Oozie parameters accessable in MapReduce

Configuration conf = getConf();
String loc = System.getProperty("oozie.action.conf.xml");
if (loc != null) {
	Path lcp = new Path(loc);
	conf.addResource(lcp);
}

In the code use conf.get("parameter name") to get the value for the parameter

Hbase related code

Mapper/Reducer reading from Hbase

Mapper

The mapper class needs to extend org.apache.hadoop.hbase.mapreduce.TableMapper<Key retured by Mapper, value returned by Mapper>
It can override following methods

protected void setup(Context context) {}
public void map(ImmutableBytesWritable row, Result value, Context context){}
protected void cleanup(Context context){}

Reducer

The reducer class needs to extend org.apache.hadoop.hbase.mapreduce.TableReducer

Hbase java api

export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:`hbase classpath` --> Before running hadoop job that connects to Hbase

For running stand alone Java code that connects to Hbase

java -cp .:<hadoop path>/share/hadoop/common/lib/*:<hbase path>/bin/../lib/*:	 <java code>

Instead of using PrefixFilter always use <scan object>.setRowPrefixFilter, the later sets the start and stop row by default which improves the performance.

Use FilterList when more than one filter needs to applied to Scan --> It supports must pass all and must pass one.

# Hbase java api code
		Configuration hconf = HBaseConfiguration.create();
		try {
			connection = ConnectionFactory.createConnection(hconf);
			myTable = connection.getTable(TableName
					.valueOf("<hbase table name>"));

		} catch (IOException e) {
			// log error and exit
		}

Oozie client java api

		System.setProperty("javax.net.ssl.trustStore", "<ssl truststore path>");
		System.setProperty("authenticator.class", "com.mapr.security.maprauth.MaprAuthenticator"); --> for mapr
		AuthOozieClient aoclient = new AuthOozieClient("oozieServer");
		Properties prop1 = aoclient.createConfiguration();
		prop1.setProperty("nameNode", "maprfs:///");
		prop1.setProperty("jobTracker", "job tracker");
		prop1.setProperty(AuthOozieClient.APP_PATH, "oozie workflow path");
		prop1.setProperty("queueName", queueName);		
		prop1.setProperty("oozie.use.system.libpath", "true");		
		try {
			String JobId = aoclient.run(prop1);			
			while (aoclient.getJobInfo(JobId).getStatus() == WorkflowJob.Status.RUNNING) {				
				Thread.sleep(30 * 1000);
			}
			if (aoclient.getJobInfo(JobId).getStatus() == WorkflowJob.Status.FAILED
					|| aoclient.getJobInfo(JobId).getStatus() == WorkflowJob.Status.KILLED) {
			
			//exit 
			}
		} catch (OozieClientException | InterruptedException w) {
			//error 
			//exit with errir
		}


Miscellaneous   
WholeFileInputFormat --> allows all the files in the input to be processed using a single mapper.


